
import pandas as pd
import csv
import numpy as np
import os
import matplotlib.pyplot as plt
import random
import torch
import json
import seaborn as sns

#REPRODUCIBILIY
def set_seed(seed=42):
    """
    The function sets the seed for random number generators in Python, NumPy, and PyTorch.
    
    :param seed: The seed parameter is an optional parameter that specifies the seed value to be used
    for random number generation. By setting a seed value, you can ensure that the random numbers
    generated by your code are reproducible, defaults to 42 (optional)
    """
    os.environ['PYTHONHASHSEED']=str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)

def make_path(pathdir):
    """
    The function creates a directory if it does not already exist.
    
    :param pathdir: The parameter `pathdir` is a string representing the directory path that you want to
    create
    """
    if not os.path.exists(pathdir):
        os.mkdir(pathdir)

#VISUALIZING THE FREQUENCY DETAILS OF THE DATA
def viz_data(full_data):
    """
    The function `viz_data` visualizes the frequency distribution of class labels in a dataset.
    
    :param full_data: The `full_data` parameter is a pandas DataFrame that contains the data you want to
    visualize. It should have a column named "BROWSE_NODE_ID" which represents the class labels for the
    data
    """
    
    class_count = dict(full_data["BROWSE_NODE_ID"].value_counts())
    counts = list(class_count.values())

    class_bins = {
        "top 50" : sum(counts[:50]),
        "50 - 100" : sum(counts[50:100]),
        "100 - 150" : sum(counts[100:150]),
        "150 - 200" : sum(counts[150:200]),
        "200 - 250" : sum(counts[200:250])
    }
    colors = sns.color_palette('pastel')[0:5]

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    fig.suptitle('Frequency Visualization', fontsize =15)

    class_count = dict(full_data["BROWSE_NODE_ID"].value_counts())
    counts = list(class_count.values())
    ax1.plot(counts)
    ax1.set_xlabel ("class indices reverse sorted by frequency", fontsize =15)
    ax1.set_ylabel("frequency", fontsize =15)
    ax1.set_title("class frequency plot", fontsize =15)

    ax2.pie(list(class_bins.values()),
            labels = list(class_bins.keys()), 
            colors = colors, autopct='%1.1f%%')
    ax2.legend(labels = list(class_bins.keys()), title="Legend", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
    ax2.set_title("Train data class bins composition", fontsize =15)

    plt.tight_layout()
    plt.show()

# CAPPING THE MAX SAMPLES PER CLASS, AND KEEPING THE MOST FREQUENT CLASSES 
def get_protov2_df(df, greater_than = 900, max_samples_per_class = 10100):
    """
    The function `get_protov2_df` takes a DataFrame `df` and returns a new DataFrame `protov2_df` that
    contains a subset of the original data based on certain conditions.
    
    :param df: The input dataframe containing the data
    :param greater_than: The "greater_than" parameter is used to filter out classes that have fewer
    samples than the specified value. Only classes with a count greater than this value will be included
    in the protov2_df dataframe, defaults to 900 (optional)
    :param max_samples_per_class: The parameter "max_samples_per_class" determines the maximum number of
    samples per class that will be included in the final protov2_df dataframe. If a class has more
    samples than this value, a random subset of samples will be selected to ensure that the maximum
    number is not exceeded, defaults to 10100 (optional)
    :return: a DataFrame called `protov2_df` that contains a subset of the original DataFrame `df`. The
    subset is created based on the following criteria:
    """
    final_df = 0
    protov2_df = pd.DataFrame()
    class_samples = df["BROWSE_NODE_ID"].value_counts()
    protov2_class_list = class_samples[class_samples.gt(greater_than)].index
    protov2_num_classes = len(protov2_class_list)
    for ind, class_id in enumerate(protov2_class_list):
        if class_samples[class_id] > max_samples_per_class:
            class_df = df[df["BROWSE_NODE_ID"] == class_id]
            percent_samples = max_samples_per_class/len(class_df)
            protov2_df = pd.concat([protov2_df, class_df.sample(frac= percent_samples, random_state = 200)])
        else:
            class_df = df[df["BROWSE_NODE_ID"] == class_id]
            percent_samples = 1
            protov2_df = pd.concat([protov2_df, class_df])
        if ind%10 == 0 and ind!= 0:    
            print(f"{ind}/{protov2_num_classes} : class id {class_id}, % of available samples : {percent_samples}, total samples added : {percent_samples * len(class_df)}")    
        if ind%50 == 0 and ind!= 0:
            print(f"\n################# samples in protov2 df : {len(protov2_df)} ##################\n")
    
    print(f"\n_________________ TOTAL SAMPLES in protov2 df : {len(protov2_df)} __________________\n")
    print(f"\n_________________ TOTAL CLASSES in protov2 df : {protov2_num_classes} __________________\n")
    print(f"\n_________________ PERCENT of total data used : {(len(protov2_df)/len(df))*100}%")
    return protov2_df.sample(frac= 1, random_state = 200)


#TEST TRAIN SPLIT
def get_data_splits(temp_df):
    """
    The function `get_data_splits` takes a DataFrame `temp_df` and splits it into a training set and a
    test set, ensuring that the test set contains a balanced number of samples for each class.
    
    :param temp_df: The `temp_df` parameter is a DataFrame that contains the data you want to split into
    train and test sets
    :return: a tuple containing two dataframes: `train_df` and `final_test_df`.
    """
    train_df = temp_df.sample(frac=0.98, random_state = 200)
    test_df = temp_df.drop(train_df.index)
    
    class_samples = test_df["BROWSE_NODE_ID"].value_counts()
    class_list = list(class_samples.index)
    train_df = train_df[train_df['BROWSE_NODE_ID'].isin(class_list)]
    
    final_test_df = pd.DataFrame()
    
    for ind, class_id in enumerate(class_list):
        if class_samples[class_id] > 25:
            class_df = test_df[test_df["BROWSE_NODE_ID"] == class_id]
            percent_samples = 25/len(class_df)
            final_test_df = pd.concat([final_test_df, class_df.sample(frac= percent_samples, random_state = 200)])
        else:
            class_df = test_df[test_df["BROWSE_NODE_ID"] == class_id]
            percent_samples = 1
            final_test_df = pd.concat([final_test_df, class_df])
        #if ind%10 == 0 and ind!= 0:    
        #    print(f"{ind}/{protov2_num_classes} : class id {class_id}, % of available samples : {percent_samples}, total samples added : {percent_samples * len(class_df)}")    
    
    return (train_df, final_test_df)